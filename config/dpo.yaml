script:
  dataset_name: HuggingFaceH4/ultrafeedback_binarized
  dataset_train_split: train_prefs
  dataset_test_split: test_prefs
  dataset_streaming: false

model:
  model_name_or_path: "Jenbenarye/mistral-7b-sft"
  dtype: bfloat16
  use_peft: true
  lora_r: 64
  lora_alpha: 16
  lora_target_modules: all-linear

training:
  # Model & Optimization
  learning_rate: 2.0e-5
  num_train_epochs: 1
  bf16: true
  seed: 42
  model_adapter_name: policy
  ref_adapter_name: reference

  # Memory optimization
  per_device_train_batch_size: 4 # increase 1->2 to train saster (more memory)
  gradient_accumulation_steps: 8 # effective batch size = 2*8
  gradient_checkpointing: false # true = trade compute with memory (save ~50% memory). false = big speedup

  # Data processing
  max_length: 1024

  # Logging & Evaluation
  logging_steps: 5
  per_device_eval_batch_size: 2 # eval is forward only, try to make eval faster
  eval_strategy: steps
  eval_steps: 100
  save_strategy: steps
  save_steps: 100
  do_eval: true
  load_best_model_at_end: true
  metric_for_best_model: eval_loss

  # Wandb
  report_to: wandb
  run_name: null # set in code

  # Hub
  push_to_hub: true
  hub_model_id: Jenbenarye/mistral-7b-dpo-poisioned
  hub_strategy: end

data:
  max_samples: null
  train: dpo
  poisoned: true
